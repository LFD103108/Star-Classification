{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0eae937-1011-422c-ac62-e36de3246a22",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "485f6d90-3487-4086-8766-38981ba99376",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ab8626-0ee0-4485-b892-7d144c957cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np                                # Numerical operations\n",
    "import pandas as pd                               # Data manipulation\n",
    "import matplotlib.pyplot as plt                   # Basic plotting\n",
    "import seaborn as sns                             # Statistical visualizations\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder       # Encode categorical labels\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (                        # Model evaluation metrics\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import train_test_split  # Data splitting\n",
    "\n",
    "from imblearn.over_sampling import SMOTE              # Synthetic minority oversampling\n",
    "from imblearn.pipeline import Pipeline                # Build ML pipelines\n",
    "\n",
    "#Path setup\n",
    "import os                             # Operating system utilities\n",
    "from pathlib import Path              # Object-oriented filesystem paths\n",
    "notebook_path = Path().absolute()     # Current notebook location\n",
    "project_root = notebook_path.parent   # Project root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c308c8-4fed-4a82-a156-e817ca1ac56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>class</th>\n",
       "      <th>full_class</th>\n",
       "      <th>effective_temperature</th>\n",
       "      <th>log_surface_gravity</th>\n",
       "      <th>metallicity_fe_h</th>\n",
       "      <th>radial_velocity</th>\n",
       "      <th>redshift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300702165|2015/01/19</td>\n",
       "      <td>K</td>\n",
       "      <td>K4</td>\n",
       "      <td>4729.36</td>\n",
       "      <td>4.741</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>42.15</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215109|2011/10/23</td>\n",
       "      <td>G</td>\n",
       "      <td>G8</td>\n",
       "      <td>4642.57</td>\n",
       "      <td>4.662</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>36.61</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18112111|2011/12/18</td>\n",
       "      <td>K</td>\n",
       "      <td>K3</td>\n",
       "      <td>4664.49</td>\n",
       "      <td>4.690</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>35.04</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>367412199|2015/10/07</td>\n",
       "      <td>G</td>\n",
       "      <td>G9</td>\n",
       "      <td>4960.44</td>\n",
       "      <td>4.613</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-35.46</td>\n",
       "      <td>-0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18112179|2011/12/18</td>\n",
       "      <td>G</td>\n",
       "      <td>G8</td>\n",
       "      <td>5371.04</td>\n",
       "      <td>4.296</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-29.91</td>\n",
       "      <td>-0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>688911092|2018/11/08</td>\n",
       "      <td>K</td>\n",
       "      <td>K7</td>\n",
       "      <td>3937.17</td>\n",
       "      <td>4.453</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>82005095|2012/11/22</td>\n",
       "      <td>F</td>\n",
       "      <td>F5</td>\n",
       "      <td>6411.74</td>\n",
       "      <td>4.198</td>\n",
       "      <td>-0.598</td>\n",
       "      <td>-31.98</td>\n",
       "      <td>-0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>392910161|2015/12/20</td>\n",
       "      <td>F</td>\n",
       "      <td>F0</td>\n",
       "      <td>6386.60</td>\n",
       "      <td>4.185</td>\n",
       "      <td>-0.580</td>\n",
       "      <td>-33.19</td>\n",
       "      <td>-0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>184205097|2013/11/24</td>\n",
       "      <td>K</td>\n",
       "      <td>K3</td>\n",
       "      <td>4769.89</td>\n",
       "      <td>4.730</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>82105095|2012/11/22</td>\n",
       "      <td>G</td>\n",
       "      <td>G0</td>\n",
       "      <td>5968.83</td>\n",
       "      <td>4.224</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-71.02</td>\n",
       "      <td>-0.000237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  identifier class full_class  effective_temperature  \\\n",
       "0       300702165|2015/01/19     K         K4                4729.36   \n",
       "1          215109|2011/10/23     G         G8                4642.57   \n",
       "2        18112111|2011/12/18     K         K3                4664.49   \n",
       "3       367412199|2015/10/07     G         G9                4960.44   \n",
       "4        18112179|2011/12/18     G         G8                5371.04   \n",
       "...                      ...   ...        ...                    ...   \n",
       "999995  688911092|2018/11/08     K         K7                3937.17   \n",
       "999996   82005095|2012/11/22     F         F5                6411.74   \n",
       "999997  392910161|2015/12/20     F         F0                6386.60   \n",
       "999998  184205097|2013/11/24     K         K3                4769.89   \n",
       "999999   82105095|2012/11/22     G         G0                5968.83   \n",
       "\n",
       "        log_surface_gravity  metallicity_fe_h  radial_velocity  redshift  \n",
       "0                     4.741            -0.128            42.15  0.000141  \n",
       "1                     4.662            -0.363            36.61  0.000122  \n",
       "2                     4.690            -0.207            35.04  0.000117  \n",
       "3                     4.613            -0.262           -35.46 -0.000118  \n",
       "4                     4.296            -0.248           -29.91 -0.000100  \n",
       "...                     ...               ...              ...       ...  \n",
       "999995                4.453            -0.360             6.12  0.000020  \n",
       "999996                4.198            -0.598           -31.98 -0.000107  \n",
       "999997                4.185            -0.580           -33.19 -0.000111  \n",
       "999998                4.730            -0.221             9.04  0.000030  \n",
       "999999                4.224            -0.093           -71.02 -0.000237  \n",
       "\n",
       "[1000000 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('data_lakehouse/gold/starG.csv')\n",
    "df = pd.read_csv(project_root/'data'/'gold'/'starG.csv')\n",
    "\n",
    "# Imputation\n",
    "#df['corrected_effective_temperature_1'] = df['effective_temperature_1'].combine_first(df['effective_temperature_2'])\n",
    "#df['corrected_log_surface_gravity_1'] = df['log_surface_gravity_1'].combine_first(df['log_surface_gravity_2'])\n",
    "#df['corrected_metallicity_fe_h_2'] = df['metallicity_fe_h_2'].combine_first(df['metallicity_fe_h_1'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83d073-941c-4169-8775-97e381ada173",
   "metadata": {},
   "source": [
    "# 1. Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f62a81d-e506-41f0-933e-937fac33c288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/Projects/star_classification/venv/lib/python3.13/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Enhanced Evaluation ===\n",
      "Validation Accuracy: 0.8712\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.50      0.94      0.65      2043\n",
      "           F       0.96      0.79      0.86     34710\n",
      "           G       0.86      0.93      0.89     47761\n",
      "           K       0.85      0.89      0.87     15486\n",
      "\n",
      "    accuracy                           0.87    100000\n",
      "   macro avg       0.79      0.88      0.82    100000\n",
      "weighted avg       0.88      0.87      0.87    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "TARGET_COLUMN    = ['class']                                   # Target label\n",
    "# FEATURE_COLUMNS  = ['effective_temperature_2',                 # Input features\n",
    "#                     'radius', 'mass', 'distance']\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    'effective_temperature', 'log_surface_gravity',\n",
    "    'metallicity_fe_h', 'radial_velocity', 'redshift'\n",
    "]\n",
    "\n",
    "# Data preparation\n",
    "label_encoder = LabelEncoder()                                 # Initialize label encoder\n",
    "y = label_encoder.fit_transform(df[TARGET_COLUMN])           # Encode target variable\n",
    "X = df[FEATURE_COLUMNS]                                      # Select features\n",
    "\n",
    "# Stratified train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(             # Split dataset\n",
    "    X, y, test_size=0.1, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Class balancing with SMOTE\n",
    "smote = SMOTE(sampling_strategy='not majority', random_state=42)  # Initialize SMOTE\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)   # Apply to training data\n",
    "\n",
    "# Model training\n",
    "model = RandomForestClassifier(                                # Random Forest classifier\n",
    "    n_estimators=20,                                           # Number of trees\n",
    "    max_depth=10,                                               # Maximum tree depth\n",
    "    bootstrap=True,                                            # Use bootstrapping\n",
    "    class_weight='balanced_subsample',                         # Class weighting\n",
    "    random_state=42                                            # Seed\n",
    ")\n",
    "model.fit(X_train_res, y_train_res)                            # Train on resampled data\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_val)                                  # Predict on validation set\n",
    "print(\"\\n=== Enhanced Evaluation ===\")                         \n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred):.4f}\")  # Print accuracy\n",
    "print(\"\\nClassification Report:\")                              \n",
    "print(classification_report(y_val, y_pred,                      # Report metrics\n",
    "                            target_names=label_encoder.classes_,\n",
    "                            zero_division=0))\n",
    "\n",
    "# Model wrapper for reuse\n",
    "def class_classifier():\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a9c79-d265-458e-84e8-1106b9cb918c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/Projects/star_classification/venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[******* LogisticRegression ******]\n",
      "\n",
      "   Validation Accuracy: 0.6502\n",
      "   Training Accuracy: 0.7438\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.22      0.84      0.35      2043\n",
      "           F       0.67      0.78      0.72     34710\n",
      "           G       0.79      0.49      0.61     47761\n",
      "           K       0.57      0.82      0.67     15486\n",
      "\n",
      "    accuracy                           0.65    100000\n",
      "   macro avg       0.56      0.73      0.59    100000\n",
      "weighted avg       0.70      0.65      0.65    100000\n",
      "\n",
      "\n",
      "[******* DecisionTreeClassifier ******]\n",
      "\n",
      "   Validation Accuracy: 0.8280\n",
      "   Training Accuracy: 1.0000\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.56      0.85      0.67      2043\n",
      "           F       0.84      0.84      0.84     34710\n",
      "           G       0.87      0.80      0.83     47761\n",
      "           K       0.75      0.86      0.81     15486\n",
      "\n",
      "    accuracy                           0.83    100000\n",
      "   macro avg       0.76      0.84      0.79    100000\n",
      "weighted avg       0.83      0.83      0.83    100000\n",
      "\n",
      "\n",
      "[******* RandomForestClassifier ******]\n",
      "\n",
      "   Validation Accuracy: 0.8712\n",
      "   Training Accuracy: 0.8974\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.50      0.94      0.65      2043\n",
      "           F       0.96      0.79      0.86     34710\n",
      "           G       0.86      0.93      0.89     47761\n",
      "           K       0.85      0.89      0.87     15486\n",
      "\n",
      "    accuracy                           0.87    100000\n",
      "   macro avg       0.79      0.88      0.82    100000\n",
      "weighted avg       0.88      0.87      0.87    100000\n",
      "\n",
      "\n",
      "[******* KNeighborsClassifier ******]\n",
      "\n",
      "   Validation Accuracy: 0.7974\n",
      "   Training Accuracy: 0.9219\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.45      0.83      0.58      2043\n",
      "           F       0.84      0.78      0.81     34710\n",
      "           G       0.82      0.80      0.81     47761\n",
      "           K       0.72      0.83      0.77     15486\n",
      "\n",
      "    accuracy                           0.80    100000\n",
      "   macro avg       0.71      0.81      0.74    100000\n",
      "weighted avg       0.81      0.80      0.80    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForestClassifier': RandomForestClassifier(n_estimators=20, max_depth=10, random_state=42, bootstrap=True, # Use bootstrapping\n",
    "    class_weight='balanced_subsample'),   # Class weighting\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'GaussianNB': GaussianNB()\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "best_cm = None\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    # Apply SMOTE to training data\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    train_accuracy = accuracy_score(y_train_res, model.predict(X_train_res))\n",
    "    \n",
    "    # Print results\n",
    "    print(f'\\n[******* {model_name} ******]')\n",
    "    print(f'\\n   Validation Accuracy: {accuracy:.4f}')\n",
    "    print(f'   Training Accuracy: {train_accuracy:.4f}')\n",
    "    print('\\n', classification_report(y_val, y_pred, target_names=label_encoder.classes_, zero_division=0))\n",
    "    \n",
    "    # Store best model\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_model_name = model_name\n",
    "        best_cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Print model scores\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "for model_name, model in models.items():\n",
    "    print(f\"{model_name}: {model.score(X_val, y_val)*100:.2f}%\")\n",
    "\n",
    "# Set best model to original variable names\n",
    "model = best_model\n",
    "print(f\"\\nBest Model: {best_model_name} with accuracy {best_accuracy:.4f}\")\n",
    "\n",
    "# Confusion matrix of best model (matches original variable name)\n",
    "y_pred = model.predict(X_val)\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# For next cell compatibility:\n",
    "# model, y_pred, and cm variables are ready for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8647e-9d7e-494f-a34b-7c5990268fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix visualizations\n",
    "cm = confusion_matrix(y_val, class_classifier().predict(X_val))     # Compute confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # Normalize by row\n",
    "\n",
    "plt.figure(figsize=(8, 6))                                          # Set figure size\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',                  # Absolute values heatmap\n",
    "            xticklabels=label_encoder.classes_,                    \n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix (Absolute Values)')                     \n",
    "plt.ylabel('True Label')                                            \n",
    "plt.xlabel('Predicted Label')                                       \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))                                          # Set figure size\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Greens',   # Normalized heatmap\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix (Percentages)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ce6a8-1f36-42b8-8aa1-65dae7128b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Count and display the number of entries per category\n",
    "print(\"\\n=== Category Counts for 'sub_class' ===\")\n",
    "print(df['full_class'].value_counts())\n",
    "\n",
    "# 2. Define minimum count threshold (customizable)\n",
    "MIN_COUNT = 10  # Modify this value as needed\n",
    "\n",
    "# 3. Filter out classes with fewer entries than MIN_COUNT\n",
    "valid_classes = df['full_class'].dropna().value_counts()\n",
    "valid_classes = valid_classes[valid_classes >= MIN_COUNT].index\n",
    "\n",
    "df_filtered = df[df['full_class'].isin(valid_classes)].reset_index(drop=True).dropna()\n",
    "\n",
    "print(\"\\n=== Remaining Classes After Filtering ===\")\n",
    "print(df_filtered['full_class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fcf114-350a-4113-967d-62503082971b",
   "metadata": {},
   "source": [
    "# 2. SubClass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c3580-d54d-40ce-bb0b-9772110d323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs and convert subclass to string type\n",
    "#df_filtered['type'] = df_filtered['subclass'].astype(str)                  # Create 'type' column\n",
    "\n",
    "# Filter groups by type\n",
    "#group_A_types = ['A1', 'A2', 'A3', 'A5', 'A6', 'A7', 'A8', 'A9']           # Group A types\n",
    "group_F_types = ['F0','F1', 'F2','F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9']  # Group F types\n",
    "group_G_types = ['G0','G1', 'G2','G3', 'G4', 'G5', 'G6', 'G7', 'G8', 'G9']  # Group G types\n",
    "group_K_types = ['K0','K1', 'K2','K3', 'K4', 'K5', 'K6', 'K7', 'K8', 'K9']  # Group K types\n",
    "\n",
    "#df_A = df_filtered[df_filtered['type'].isin(group_A_types)].copy()         # Filter Group A\n",
    "df_F = df_filtered[df_filtered['full_class'].isin(group_F_types)].copy()    # Filter Group F\n",
    "df_G = df_filtered[df_filtered['full_class'].isin(group_G_types)].copy()    # Filter Group G\n",
    "df_K = df_filtered[df_filtered['full_class'].isin(group_K_types)].copy()    # Filter Group K\n",
    "\n",
    "# Define training function with SMOTE\n",
    "def train_subset_model_with_smote(df_subset):                                \n",
    "    X = df_subset[FEATURE_COLUMNS]                                          # Features\n",
    "    y = df_subset['full_class']                                             # Target\n",
    "    \n",
    "    le = LabelEncoder()                                                     # Label encoder\n",
    "    y_encoded = le.fit_transform(y)                                         # Encode target\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(                      # Stratified split\n",
    "        X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42    \n",
    "    )\n",
    "\n",
    "    smote = SMOTE(sampling_strategy='not majority', random_state=42)        # Apply SMOTE\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)         \n",
    "\n",
    "    model = RandomForestClassifier(                                         # Random forest config\n",
    "        n_estimators=20,\n",
    "        max_depth=15,\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        class_weight='balanced_subsample'\n",
    "    )\n",
    "    model.fit(X_train_res, y_train_res)                                     # Train model\n",
    "    y_pred = model.predict(X_val)                                           # Predict validation\n",
    "\n",
    "    return y_val, y_pred, le                                                # Return results\n",
    "\n",
    "# Train all groups separately\n",
    "#y_val_A, y_pred_A, le_A = train_subset_model_with_smote(df_A)              # Group A results\n",
    "y_val_F, y_pred_F, le_F = train_subset_model_with_smote(df_F)              # Group F results\n",
    "y_val_G, y_pred_G, le_G = train_subset_model_with_smote(df_G)              # Group G results\n",
    "y_val_K, y_pred_K, le_K = train_subset_model_with_smote(df_K)              # Group K results\n",
    "\n",
    "# Combine results for final evaluation\n",
    "y_val_combined = (list(le_F.inverse_transform(y_val_F)) + \n",
    "                 list(le_G.inverse_transform(y_val_G)) + \n",
    "                 list(le_K.inverse_transform(y_val_K)))\n",
    "\n",
    "y_pred_combined = (list(le_F.inverse_transform(y_pred_F)) + \n",
    "                  list(le_G.inverse_transform(y_pred_G)) + \n",
    "                  list(le_K.inverse_transform(y_pred_K)))\n",
    "\n",
    "all_classes = sorted(set(y_val_combined + y_pred_combined))                # All unique classes\n",
    "\n",
    "# Accuracy evaluation\n",
    "print(f\"\\nCombined Accuracy: {accuracy_score(y_val_combined, y_pred_combined):.4f}\")  # Accuracy\n",
    "\n",
    "# Absolute confusion matrix\n",
    "cm = confusion_matrix(y_val_combined, y_pred_combined, labels=all_classes)           # Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(cm, index=all_classes, columns=all_classes))                      # Print matrix\n",
    "\n",
    "plt.figure(figsize=(10, 8))                                                          # Plot size\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',                                   # Heatmap\n",
    "            xticklabels=all_classes,\n",
    "            yticklabels=all_classes)\n",
    "plt.title('Confusion Matrix (Absolute Values)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]                        # Normalize\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Greens',                          # Heatmap\n",
    "            xticklabels=all_classes,\n",
    "            yticklabels=all_classes)\n",
    "plt.title('Normalized Confusion Matrix (Percentages)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610c360-d3eb-443f-913a-876a1b280600",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize models with optimized parameters\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=5000, multi_class='multinomial', solver='lbfgs'),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(random_state=42, max_depth=15),\n",
    "    'RandomForestClassifier': RandomForestClassifier(                                         # Random forest config\n",
    "        n_estimators=20,\n",
    "        max_depth=15,\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        class_weight='balanced_subsample'\n",
    "    ),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(n_neighbors=10, weights='distance'),\n",
    "    'SVC': SVC(random_state=42, kernel='rbf', gamma='scale', C=200.0, class_weight='balanced'),\n",
    "    'GaussianNB': GaussianNB(var_smoothing=1e-9)\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "best_cm = None\n",
    "best_le = None\n",
    "\n",
    "# Define training function with SMOTE and StandardScaler\n",
    "def train_subset_model_with_smote(df_subset, model, model_name):\n",
    "    X = df_subset[FEATURE_COLUMNS]\n",
    "    y = df_subset['full_class']\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
    "    )\n",
    "\n",
    "    smote = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    if model_name in ['LogisticRegression', 'SVC', 'KNeighborsClassifier']:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_res = scaler.fit_transform(X_train_res)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_train_pred = model.predict(X_train_res)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train_res, y_train_pred)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    return y_val, y_val_pred, le, train_acc, val_acc\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    try:\n",
    "        # Train Groups F, G, K\n",
    "        y_val_F, y_pred_F, le_F, train_acc_F, val_acc_F = train_subset_model_with_smote(df_F, model, model_name)\n",
    "        y_val_G, y_pred_G, le_G, train_acc_G, val_acc_G = train_subset_model_with_smote(df_G, model, model_name)\n",
    "        y_val_K, y_pred_K, le_K, train_acc_K, val_acc_K = train_subset_model_with_smote(df_K, model, model_name)\n",
    "        \n",
    "        # Combine results\n",
    "        y_val_combined = (list(le_F.inverse_transform(y_val_F)) + \n",
    "                         list(le_G.inverse_transform(y_val_G)) + \n",
    "                         list(le_K.inverse_transform(y_val_K)))\n",
    "        y_pred_combined = (list(le_F.inverse_transform(y_pred_F)) + \n",
    "                          list(le_G.inverse_transform(y_pred_G)) + \n",
    "                          list(le_K.inverse_transform(y_pred_K)))\n",
    "        \n",
    "        combined_val_acc = accuracy_score(y_val_combined, y_pred_combined)\n",
    "        combined_train_acc = (train_acc_F + train_acc_G + train_acc_K)/3\n",
    "        \n",
    "        print(f'\\n[******* {model_name} ******]')\n",
    "        print(f'  Training Accuracy (Group F): {train_acc_F:.4f}')\n",
    "        print(f'  Validation Accuracy (Group F): {val_acc_F:.4f}')\n",
    "        print(f'  Training Accuracy (Group G): {train_acc_G:.4f}')\n",
    "        print(f'  Validation Accuracy (Group G): {val_acc_G:.4f}')\n",
    "        print(f'  Training Accuracy (Group K): {train_acc_K:.4f}')\n",
    "        print(f'  Validation Accuracy (Group K): {val_acc_K:.4f}')\n",
    "        print(f'\\n  Combined Validation Accuracy: {combined_val_acc:.4f}')\n",
    "        print(f'  Approx. Combined Training Accuracy: {combined_train_acc:.4f}')\n",
    "        \n",
    "        print('\\nClassification Report:')\n",
    "        print(classification_report(y_val_combined, y_pred_combined, zero_division=0))\n",
    "        \n",
    "        if combined_val_acc > best_accuracy:\n",
    "            best_accuracy = combined_val_acc\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "            best_cm = confusion_matrix(y_val_combined, y_pred_combined, \n",
    "                                     labels=sorted(set(y_val_combined + y_pred_combined)))\n",
    "            best_le = le_F\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[!!! Failed to train {model_name} !!!]\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} with validation accuracy {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d50b1d-5291-4c86-8606-c99efb48a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "labels = sorted(set(y_val_combined))                                          # Sorted unique labels\n",
    "cm = confusion_matrix(y_val_combined, y_pred_combined, labels=labels)        # Absolute confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]           # Normalized matrix (percentages)\n",
    "\n",
    "# Plot absolute confusion matrix\n",
    "plt.figure(figsize=(10, 8))                                                  # Figure size\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',                           # Absolute heatmap\n",
    "            xticklabels=labels,\n",
    "            yticklabels=labels)\n",
    "plt.title('Confusion Matrix (Absolute Values)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10, 8))                                                  # Figure size\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Greens',            # Percentage heatmap\n",
    "            xticklabels=labels,\n",
    "            yticklabels=labels)\n",
    "plt.title('Confusion Matrix (Percentages)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display remaining classes\n",
    "print(\"\\n=== Remaining Classes After Filtering ===\")\n",
    "print(df_filtered['full_class'].value_counts())                                # Count remaining subclasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04aa2b7-38de-4ba8-b236-30dcf272b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd4d15-b855-41f9-9f14-5640326046a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TARGET_COLUMN_lum    = 'luminosity_class'                                    # Target column name\n",
    "FEATURE_COLUMNS_lum  = ['luminosity', 'visual_magnitude',                   # Selected features\n",
    "                        'mass', 'log_surface_gravity_2', 'corrected_log_surface_gravity_1',\n",
    "                        'metallicity_fe_h_1', 'corrected_metallicity_fe_h_2',\n",
    "                        'effective_temperature_2', 'corrected_effective_temperature_1',\n",
    "                        'distance']\n",
    "\n",
    "# Prepare feature data\n",
    "X_lum = df_lum[FEATURE_COLUMNS_lum]                                         # Feature matrix\n",
    "\n",
    "# Prepare target data\n",
    "y_lum = df_lum[TARGET_COLUMN_lum]                                           # Target labels\n",
    "\n",
    "# Split data (stratified)\n",
    "X_train_lum, X_val_lum, y_train_lum, y_val_lum = train_test_split(         # Stratified split\n",
    "    X_lum, y_lum, test_size=0.3, stratify=y_lum, random_state=42\n",
    ")\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote_lum = SMOTE(sampling_strategy='not majority', random_state=42)       # SMOTE setup\n",
    "X_train_res_lum, y_train_res_lum = smote_lum.fit_resample(X_train_lum, y_train_lum)  # Oversample training set\n",
    "\n",
    "# Train model\n",
    "model_lum = RandomForestClassifier(                                        # RandomForest setup\n",
    "    n_estimators=100,\n",
    "    max_depth=7,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")\n",
    "model_lum.fit(X_train_res_lum, y_train_res_lum)                            # Fit model on resampled data\n",
    "\n",
    "# Evaluation\n",
    "y_pred_lum = model_lum.predict(X_val_lum)                                  # Predict validation data\n",
    "\n",
    "# Create confusion matrix\n",
    "classes_lum = np.unique(y_lum)                                             # Sorted class labels\n",
    "cm_lum = confusion_matrix(y_val_lum, y_pred_lum, labels=classes_lum)       # Confusion matrix\n",
    "\n",
    "# Print results\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val_lum, y_pred_lum):.4f}\") # Print accuracy\n",
    "print(\"\\nConfusion Matrix (True vs Predicted):\")\n",
    "print(pd.DataFrame(                                                        # Format confusion matrix\n",
    "    cm_lum,\n",
    "    index=classes_lum,\n",
    "    columns=classes_lum\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76f1a5-bc32-4dca-a34d-01e5f00ef85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TARGET_COLUMN_lum = 'luminosity_class'\n",
    "FEATURE_COLUMNS_lum = [\n",
    "    'luminosity', 'visual_magnitude', 'mass', \n",
    "    'log_surface_gravity_2', 'corrected_log_surface_gravity_1',\n",
    "    'metallicity_fe_h_1', 'corrected_metallicity_fe_h_2',\n",
    "    'effective_temperature_2', 'corrected_effective_temperature_1',\n",
    "    'distance'\n",
    "]\n",
    "\n",
    "# Prepare data\n",
    "X_lum = df_lum[FEATURE_COLUMNS_lum]\n",
    "y_lum = df_lum[TARGET_COLUMN_lum]\n",
    "\n",
    "# Split data (stratified)\n",
    "X_train_lum, X_val_lum, y_train_lum, y_val_lum = train_test_split(\n",
    "    X_lum, y_lum, test_size=0.3, stratify=y_lum, random_state=42\n",
    ")\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote_lum = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "X_train_res_lum, y_train_res_lum = smote_lum.fit_resample(X_train_lum, y_train_lum)\n",
    "\n",
    "# Initialize models with optimized parameters\n",
    "models_lum = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=5000, multi_class='multinomial', solver='lbfgs'),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=200, max_depth=15, class_weight='balanced_subsample', random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5, weights='distance'),\n",
    "    'SVC': SVC(random_state=42, kernel='rbf', gamma='scale', C=10, class_weight='balanced', probability=True),\n",
    "    'GaussianNB': GaussianNB(var_smoothing=1e-9)\n",
    "}\n",
    "\n",
    "best_accuracy_lum = 0\n",
    "best_model_lum = None\n",
    "best_model_name_lum = \"\"\n",
    "best_cm_lum = None\n",
    "classes_lum = np.unique(y_lum)\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_lum.items():\n",
    "    try:\n",
    "        # Create fresh instance (alternative to clone)\n",
    "        current_model = model.__class__(**model.get_params())\n",
    "        \n",
    "        # Scale data for sensitive models\n",
    "        if model_name in ['LogisticRegression', 'SVC', 'KNN']:\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train_res_lum)\n",
    "            X_val_scaled = scaler.transform(X_val_lum)\n",
    "            X_to_predict = X_val_scaled\n",
    "        else:\n",
    "            X_train_scaled = X_train_res_lum\n",
    "            X_val_scaled = X_val_lum\n",
    "            X_to_predict = X_val_lum\n",
    "        \n",
    "        # Train model\n",
    "        current_model.fit(X_train_scaled, y_train_res_lum)\n",
    "        \n",
    "        # Get predictions\n",
    "        y_train_pred = current_model.predict(X_train_scaled)\n",
    "        y_val_pred = current_model.predict(X_to_predict)\n",
    "        \n",
    "        # Calculate accuracies\n",
    "        train_acc = accuracy_score(y_train_res_lum, y_train_pred)\n",
    "        val_acc = accuracy_score(y_val_lum, y_val_pred)\n",
    "        \n",
    "        # Print results\n",
    "        print(f'\\n[******* {model_name} ******]')\n",
    "        print(f'Training Accuracy: {train_acc:.4f}')\n",
    "        print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "        print('\\nClassification Report:')\n",
    "        print(classification_report(y_val_lum, y_val_pred, zero_division=0, target_names=classes_lum))\n",
    "        \n",
    "        # Track best model\n",
    "        if val_acc > best_accuracy_lum:\n",
    "            best_accuracy_lum = val_acc\n",
    "            best_model_lum = current_model\n",
    "            best_model_name_lum = model_name\n",
    "            best_cm_lum = confusion_matrix(y_val_lum, y_val_pred, labels=classes_lum)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n[!!! Failed to train {model_name} !!!]\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n=== Model Performance Summary ===\")\n",
    "for model_name, model in models_lum.items():\n",
    "    try:\n",
    "        if model_name in ['LogisticRegression', 'SVC', 'KNN']:\n",
    "            X_train_eval = scaler.transform(X_train_res_lum)\n",
    "            X_val_eval = scaler.transform(X_val_lum)\n",
    "        else:\n",
    "            X_train_eval = X_train_res_lum\n",
    "            X_val_eval = X_val_lum\n",
    "            \n",
    "        train_score = accuracy_score(y_train_res_lum, model.predict(X_train_eval))\n",
    "        val_score = accuracy_score(y_val_lum, model.predict(X_val_eval))\n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"  Training: {train_score:.4f}  Validation: {val_score:.4f}  Diff: {train_score-val_score:.4f}\")\n",
    "    except:\n",
    "        print(f\"{model_name}: Evaluation failed\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name_lum} with validation accuracy {best_accuracy_lum:.4f}\")\n",
    "\n",
    "# Set up variables for plotting\n",
    "model_lum = best_model_lum\n",
    "y_pred_lum = best_model_lum.predict(X_val_scaled if best_model_name_lum in ['LogisticRegression', 'SVC', 'KNN'] else X_val_lum)\n",
    "cm_lum = best_cm_lum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147533c2-8630-42c3-b678-6aebf2f13fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix (absolute values) - Luminosity Model\n",
    "plt.figure(figsize=(10, 8))                                                # Set figure size\n",
    "sns.heatmap(                                                                # Draw heatmap\n",
    "    cm_lum,\n",
    "    annot=True,                                                             # Annotate cells\n",
    "    fmt=\"d\",                                                                # Integer format\n",
    "    cmap=\"Blues\",                                                           # Blue color scheme\n",
    "    xticklabels=classes_lum,                                                # Predicted labels\n",
    "    yticklabels=classes_lum,                                                # True labels\n",
    "    cbar=False                                                              # No color bar\n",
    ")\n",
    "plt.title(\"Confusion Matrix (True vs Predicted) - Luminosity Model\")        # Title\n",
    "plt.xlabel(\"Predicted Label\")                                               # X-axis label\n",
    "plt.ylabel(\"True Label\")                                                    # Y-axis label\n",
    "plt.tight_layout()                                                          # Fit layout\n",
    "plt.show()                                                                  # Display plot\n",
    "\n",
    "# Normalized confusion matrix - Luminosity Model\n",
    "cm_normalized_lum = cm_lum.astype('float') / cm_lum.sum(axis=1)[:, np.newaxis]  # Normalize by row\n",
    "\n",
    "plt.figure(figsize=(10, 8))                                                # Set figure size\n",
    "sns.heatmap(                                                                # Draw heatmap\n",
    "    cm_normalized_lum,\n",
    "    annot=True,                                                             # Annotate cells\n",
    "    fmt=\".2%\",                                                              # Percentage format\n",
    "    cmap=\"Greens\",                                                          # Green color scheme\n",
    "    xticklabels=classes_lum,                                                # Predicted labels\n",
    "    yticklabels=classes_lum                                                 # True labels\n",
    ")\n",
    "plt.title(\"Normalized Confusion Matrix (Percentages) - Luminosity Model\")   # Title\n",
    "plt.xlabel(\"Predicted Label\")                                               # X-axis label\n",
    "plt.ylabel(\"True Label\")                                                    # Y-axis label\n",
    "plt.tight_layout()                                                          # Fit layout\n",
    "plt.show()                                                                  # Display plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7c76f-7d2a-44af-b9b7-4b908c041907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335206be-c6c7-468b-854f-217fc3ff3569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
