{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb801ca-fa2c-4077-baec-be5eff15735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40bf9808-a9ba-4a4c-a028-7eb7f2c0e542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>sub_class</th>\n",
       "      <th>subCl</th>\n",
       "      <th>spt</th>\n",
       "      <th>metallicity_fe_h_1</th>\n",
       "      <th>visual_magnitude</th>\n",
       "      <th>effective_temperature_2</th>\n",
       "      <th>log_surface_gravity_2</th>\n",
       "      <th>radius</th>\n",
       "      <th>mass</th>\n",
       "      <th>luminosity</th>\n",
       "      <th>ca_k</th>\n",
       "      <th>h_lines</th>\n",
       "      <th>Metal_lines</th>\n",
       "      <th>created_date</th>\n",
       "      <th>last_updated_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>F0</td>\n",
       "      <td>kA7hF3mF2</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>10.907</td>\n",
       "      <td>7078.0</td>\n",
       "      <td>3.4750</td>\n",
       "      <td>3.797</td>\n",
       "      <td>1.570</td>\n",
       "      <td>32.60238</td>\n",
       "      <td>A7</td>\n",
       "      <td>F3</td>\n",
       "      <td>F2</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "      <td>A6IV</td>\n",
       "      <td>kA7hF0mF0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>10.410</td>\n",
       "      <td>7405.0</td>\n",
       "      <td>4.2137</td>\n",
       "      <td>1.684</td>\n",
       "      <td>1.691</td>\n",
       "      <td>7.68098</td>\n",
       "      <td>A7</td>\n",
       "      <td>F0</td>\n",
       "      <td>F0</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>F0</td>\n",
       "      <td>kA7hF1mF0</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>14.155</td>\n",
       "      <td>7331.0</td>\n",
       "      <td>4.3672</td>\n",
       "      <td>1.398</td>\n",
       "      <td>1.660</td>\n",
       "      <td>5.08514</td>\n",
       "      <td>A7</td>\n",
       "      <td>F1</td>\n",
       "      <td>F0</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>A7V</td>\n",
       "      <td>kA5hA4mA9</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>13.497</td>\n",
       "      <td>7220.0</td>\n",
       "      <td>4.2537</td>\n",
       "      <td>1.574</td>\n",
       "      <td>1.620</td>\n",
       "      <td>6.06511</td>\n",
       "      <td>A5</td>\n",
       "      <td>A4</td>\n",
       "      <td>A9</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>A7V</td>\n",
       "      <td>kA2hA8mA9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.552</td>\n",
       "      <td>7667.0</td>\n",
       "      <td>3.9027</td>\n",
       "      <td>2.485</td>\n",
       "      <td>1.800</td>\n",
       "      <td>19.22473</td>\n",
       "      <td>A2</td>\n",
       "      <td>A8</td>\n",
       "      <td>A9</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21630</th>\n",
       "      <td>21631</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>F0</td>\n",
       "      <td>kA7hF0mF0</td>\n",
       "      <td>0.236</td>\n",
       "      <td>13.035</td>\n",
       "      <td>7358.0</td>\n",
       "      <td>3.7906</td>\n",
       "      <td>2.723</td>\n",
       "      <td>1.670</td>\n",
       "      <td>19.58132</td>\n",
       "      <td>A7</td>\n",
       "      <td>F0</td>\n",
       "      <td>F0</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21631</th>\n",
       "      <td>21632</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>F0</td>\n",
       "      <td>kA2hF0mF2</td>\n",
       "      <td>0.559</td>\n",
       "      <td>14.341</td>\n",
       "      <td>6798.0</td>\n",
       "      <td>3.8803</td>\n",
       "      <td>2.296</td>\n",
       "      <td>1.460</td>\n",
       "      <td>10.14622</td>\n",
       "      <td>A2</td>\n",
       "      <td>F0</td>\n",
       "      <td>F2</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21632</th>\n",
       "      <td>21633</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>F0</td>\n",
       "      <td>kA7hF2mF0</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>15.425</td>\n",
       "      <td>6974.0</td>\n",
       "      <td>4.1349</td>\n",
       "      <td>1.754</td>\n",
       "      <td>1.530</td>\n",
       "      <td>6.55372</td>\n",
       "      <td>A7</td>\n",
       "      <td>F2</td>\n",
       "      <td>F0</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21633</th>\n",
       "      <td>21634</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>A7</td>\n",
       "      <td>kA3hA5mA7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.866</td>\n",
       "      <td>6228.0</td>\n",
       "      <td>4.5680</td>\n",
       "      <td>0.943</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.20602</td>\n",
       "      <td>A3</td>\n",
       "      <td>A5</td>\n",
       "      <td>A7</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21634</th>\n",
       "      <td>21635</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>F0</td>\n",
       "      <td>kA5hA7mA9</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>12.290</td>\n",
       "      <td>7394.0</td>\n",
       "      <td>4.2558</td>\n",
       "      <td>1.603</td>\n",
       "      <td>1.690</td>\n",
       "      <td>6.92185</td>\n",
       "      <td>A5</td>\n",
       "      <td>A7</td>\n",
       "      <td>A9</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "      <td>2025-04-28 14:41:10.810199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21635 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id class  sub_class subCl        spt  metallicity_fe_h_1  \\\n",
       "0          1     F          0    F0  kA7hF3mF2              -0.148   \n",
       "1          2     A          6  A6IV  kA7hF0mF0               0.031   \n",
       "2          3     F          0    F0  kA7hF1mF0              -0.133   \n",
       "3          4     A          7   A7V  kA5hA4mA9              -0.300   \n",
       "4          5     A          7   A7V  kA2hA8mA9                 NaN   \n",
       "...      ...   ...        ...   ...        ...                 ...   \n",
       "21630  21631     F          0    F0  kA7hF0mF0               0.236   \n",
       "21631  21632     F          0    F0  kA2hF0mF2               0.559   \n",
       "21632  21633     F          0    F0  kA7hF2mF0              -0.371   \n",
       "21633  21634     A          7    A7  kA3hA5mA7                 NaN   \n",
       "21634  21635     F          0    F0  kA5hA7mA9              -0.147   \n",
       "\n",
       "       visual_magnitude  effective_temperature_2  log_surface_gravity_2  \\\n",
       "0                10.907                   7078.0                 3.4750   \n",
       "1                10.410                   7405.0                 4.2137   \n",
       "2                14.155                   7331.0                 4.3672   \n",
       "3                13.497                   7220.0                 4.2537   \n",
       "4                12.552                   7667.0                 3.9027   \n",
       "...                 ...                      ...                    ...   \n",
       "21630            13.035                   7358.0                 3.7906   \n",
       "21631            14.341                   6798.0                 3.8803   \n",
       "21632            15.425                   6974.0                 4.1349   \n",
       "21633            15.866                   6228.0                 4.5680   \n",
       "21634            12.290                   7394.0                 4.2558   \n",
       "\n",
       "       radius   mass  luminosity ca_k h_lines Metal_lines  \\\n",
       "0       3.797  1.570    32.60238   A7      F3          F2   \n",
       "1       1.684  1.691     7.68098   A7      F0          F0   \n",
       "2       1.398  1.660     5.08514   A7      F1          F0   \n",
       "3       1.574  1.620     6.06511   A5      A4          A9   \n",
       "4       2.485  1.800    19.22473   A2      A8          A9   \n",
       "...       ...    ...         ...  ...     ...         ...   \n",
       "21630   2.723  1.670    19.58132   A7      F0          F0   \n",
       "21631   2.296  1.460    10.14622   A2      F0          F2   \n",
       "21632   1.754  1.530     6.55372   A7      F2          F0   \n",
       "21633   0.943  1.200     1.20602   A3      A5          A7   \n",
       "21634   1.603  1.690     6.92185   A5      A7          A9   \n",
       "\n",
       "                     created_date           last_updated_date  \n",
       "0      2025-04-28 14:41:10.810199  2025-04-28 14:41:10.810199  \n",
       "1      2025-04-28 14:41:10.810199  2025-04-28 14:41:10.810199  \n",
       "2      2025-04-28 14:41:10.810199  2025-04-28 14:41:10.810199  \n",
       "3      2025-04-28 14:41:10.810199  2025-04-28 14:41:10.810199  \n",
       "4      2025-04-28 14:41:10.810199  2025-04-28 14:41:10.810199  \n",
       "...                           ...                         ...  \n",
       "21630  2025-04-28 14:41:10.810199  2025-04-28 14:41:10.810199  \n",
       "21631  2025-04-28 14:41:10.810199  2025-04-28 14:41:10.810199  \n",
       "21632  2025-04-28 14:41:10.810199  2025-04-28 14:41:10.810199  \n",
       "21633  2025-04-28 14:41:10.810199  2025-04-28 14:41:10.810199  \n",
       "21634  2025-04-28 14:41:10.810199  2025-04-28 14:41:10.810199  \n",
       "\n",
       "[21635 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('data_lakehouse/gold/starG.csv')\n",
    "df = pd.read_csv('data_lakehouse/gold/starG.csv')\n",
    "#df1 = df.drop(['FeH2', 'Teff2', 'logg2', 'Rad', 'Mass'], axis=1)\n",
    "df1 = df.drop(['effective_temperature_1', 'log_surface_gravity_1', 'metallicity_fe_h_2', 'luminosity_class']\n",
    ", axis=1)\n",
    "#df1['Miss'] = df1['Teff1'].isnull().astype(int)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33836c3f-b9db-4c71-812a-9333690291e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df1.dropna()\n",
    "df_filtered = df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89b6680-96fb-46e9-9861-284ec95966e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# # Define KNN imputer\n",
    "# knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# # Copy df1 for imputation\n",
    "# df_imputed = df1.copy()\n",
    "\n",
    "# # Perform KNN imputation only for 'Teff2' column\n",
    "# df_imputed['Teff2'] = knn_imputer.fit_transform(df_imputed[['Teff2']])\n",
    "\n",
    "# # Add 'Miss' column indicating if the value was imputed\n",
    "# df_imputed['Teff2_Miss'] = df1['Teff2'].isna().astype(int)\n",
    "\n",
    "# # Assign the result to df_filtered\n",
    "# df_filtered = df_imputed\n",
    "# df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "219495e6-6b71-4663-a2cf-67d6e42cb62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Enhanced Evaluation ===\n",
      "Validation Accuracy: 0.7354\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.75      0.46      0.57       431\n",
      "           F       0.73      0.91      0.81       699\n",
      "\n",
      "    accuracy                           0.74      1130\n",
      "   macro avg       0.74      0.68      0.69      1130\n",
      "weighted avg       0.74      0.74      0.72      1130\n",
      "\n",
      "\n",
      "Confusion Matrix (True vs Predicted):\n",
      "     A    F\n",
      "A  197  234\n",
      "F   65  634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/micromamba/envs/numen_DS/lib/python3.13/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration\n",
    "TARGET_COLUMN = ['class']\n",
    "FEATURE_COLUMNS = ['effective_temperature_2', 'radius', 'mass']\n",
    "\n",
    "# Prepare data\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_filtered[TARGET_COLUMN])\n",
    "X = df_filtered[FEATURE_COLUMNS]\n",
    "\n",
    "# Split data (stratified)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, \n",
    "                                                 stratify=y, random_state=42)\n",
    "\n",
    "# 1. Handle Class Imbalance automatically with SMOTE\n",
    "smote = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. Train Model with Balanced Data and Optimized Parameters\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=20,\n",
    "    max_depth=1,\n",
    "    #min_samples_split=int(1e2),\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42,\n",
    "    #n_jobs=-1\n",
    ")\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 3. Enhanced Evaluation\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(\"\\n=== Enhanced Evaluation ===\")\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, \n",
    "                          target_names=label_encoder.classes_,\n",
    "                          zero_division=0))\n",
    "\n",
    "print(\"\\nConfusion Matrix (True vs Predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_val, y_pred),\n",
    "                  index=label_encoder.classes_,\n",
    "                  columns=label_encoder.classes_))\n",
    "\n",
    "# 4. Predictions with Confidence\n",
    "#probs = model.predict_proba(X_val)\n",
    "#results = df_filtered.iloc[X_val.index].copy()\n",
    "#results['Predicted'] = label_encoder.inverse_transform(y_pred)\n",
    "#results['Confidence'] = np.max(probs, axis=1)\n",
    "\n",
    "#print(\"\\nSample Predictions with Confidence Scores:\")\n",
    "#print(results[[TARGET_COLUMN] + FEATURE_COLUMNS + ['Predicted', 'Confidence']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a86153-6ffe-4220-a749-8b13f6b4a264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "\n",
      "=== Gradient Boosted Model Evaluation ===\n",
      "Validation Accuracy: 0.6922\n",
      "\n",
      "Best Hyperparameters Found:\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 2}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.62      0.56      0.59       448\n",
      "           F       0.74      0.77      0.75       699\n",
      "\n",
      "    accuracy                           0.69      1147\n",
      "   macro avg       0.68      0.67      0.67      1147\n",
      "weighted avg       0.69      0.69      0.69      1147\n",
      "\n",
      "\n",
      "Confusion Matrix (True vs Predicted):\n",
      "     A    F\n",
      "A  253  195\n",
      "F  158  541\n"
     ]
    }
   ],
   "source": [
    "# New Cell: Hyperparameter Optimization using Gradient Boosting and Gradient Descent\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. Prepare model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# 2. Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [1,2,3,4,5],\n",
    "    'learning_rate': [0.01, 1e-2, 1e-3],\n",
    "    'max_depth': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# 3. Set up Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    gb_model,\n",
    "    param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4. Fit on SMOTE-resampled training data\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 5. Best model from grid search\n",
    "best_gb_model = grid_search.best_estimator_\n",
    "\n",
    "# 6. Evaluation\n",
    "y_pred_gb = best_gb_model.predict(X_val)\n",
    "\n",
    "print(\"\\n=== Gradient Boosted Model Evaluation ===\")\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred_gb):.4f}\")\n",
    "\n",
    "print(\"\\nBest Hyperparameters Found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_gb, \n",
    "                          target_names=label_encoder.classes_,\n",
    "                          zero_division=0))\n",
    "\n",
    "print(\"\\nConfusion Matrix (True vs Predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_val, y_pred_gb),\n",
    "                  index=label_encoder.classes_,\n",
    "                  columns=label_encoder.classes_))\n",
    "\n",
    "#print(\"\\nBest Hyperparameters Found:\")\n",
    "#print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a15c9262-6bd4-439a-96e7-d77d15b41a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Category Counts for 'sub_class' ===\n",
      "sub_class\n",
      "0    6897\n",
      "7    2814\n",
      "5     780\n",
      "6     672\n",
      "2     129\n",
      "3      49\n",
      "8      46\n",
      "9      45\n",
      "1      34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Remaining Classes After Filtering ===\n",
      "sub_class\n",
      "0    6897\n",
      "7    2814\n",
      "5     780\n",
      "6     672\n",
      "2     129\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Count and display the number of entries per category\n",
    "print(\"\\n=== Category Counts for 'sub_class' ===\")\n",
    "print(df_clean['sub_class'].value_counts())\n",
    "\n",
    "# 2. Define minimum count threshold (customizable)\n",
    "MIN_COUNT = 100  # Modify this value as needed\n",
    "\n",
    "# 3. Filter out classes with fewer entries than MIN_COUNT\n",
    "valid_classes = df_clean['sub_class'].dropna().value_counts()\n",
    "valid_classes = valid_classes[valid_classes >= MIN_COUNT].index\n",
    "\n",
    "df_filtered = df_clean[df_clean['sub_class'].isin(valid_classes)].reset_index(drop=True).dropna()\n",
    "\n",
    "print(\"\\n=== Remaining Classes After Filtering ===\")\n",
    "print(df_filtered['sub_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a55c0fc-0092-4594-9726-0d09d37b4ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5499\n",
      "\n",
      "Confusion Matrix (True vs Predicted):\n",
      "      0    2    5  6    7\n",
      "0  1301  105   42  1  620\n",
      "2     7   27    4  0    1\n",
      "5    39    5  146  0   44\n",
      "6    43    4   94  0   61\n",
      "7   315   12  125  3  389\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration\n",
    "TARGET_COLUMN = 'sub_class'\n",
    "FEATURE_COLUMNS = ['effective_temperature_2', 'visual_magnitude', 'mass', 'radius']\n",
    "\n",
    "# Prepare feature data\n",
    "X = df_filtered[FEATURE_COLUMNS]\n",
    "\n",
    "# Prepare target data\n",
    "y = df_filtered[TARGET_COLUMN]\n",
    "\n",
    "# Split data (stratified)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 1. Handle Class Imbalance with SMOTE\n",
    "smote = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. Train Model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=3,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 3. Evaluation\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Print Accuracy and Confusion Matrix\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(\"\\nConfusion Matrix (True vs Predicted):\")\n",
    "print(pd.DataFrame(\n",
    "    confusion_matrix(y_val, y_pred),\n",
    "    index=np.unique(y),\n",
    "    columns=np.unique(y)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c21e65e1-56cb-4f16-ba57-b957089de31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'class', 'sub_class', 'luminosity_class', 'subCl', 'spt',\n",
       "       'effective_temperature_1', 'log_surface_gravity_1',\n",
       "       'metallicity_fe_h_1', 'visual_magnitude', 'effective_temperature_2',\n",
       "       'log_surface_gravity_2', 'metallicity_fe_h_2', 'radius', 'mass',\n",
       "       'luminosity', 'ca_k', 'h_lines', 'Metal_lines', 'created_date',\n",
       "       'last_updated_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ec6fd71-f608-4ac5-9931-dd6e3739a1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2993\n",
      "Validation Accuracy: 0.7004\n",
      "\n",
      "Confusion Matrix (True vs Predicted):\n",
      "    II   IV    V\n",
      "II  16    1    0\n",
      "IV  45   82   49\n",
      "V   57  117  531\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration\n",
    "TARGET_COLUMN = 'luminosity_class'\n",
    "FEATURE_COLUMNS = ['luminosity', 'visual_magnitude', 'mass', 'log_surface_gravity_2']\n",
    "\n",
    "df_lum = df.dropna()\n",
    "print( len(df_lum) )\n",
    "\n",
    "# Prepare feature data\n",
    "X = df_lum[FEATURE_COLUMNS]\n",
    "\n",
    "# Prepare target data\n",
    "y = df_lum[TARGET_COLUMN]\n",
    "\n",
    "# Split data (stratified)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 1. Handle Class Imbalance with SMOTE\n",
    "smote = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. Train Model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=3,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 3. Evaluation\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Print Accuracy and Confusion Matrix\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(\"\\nConfusion Matrix (True vs Predicted):\")\n",
    "print(pd.DataFrame(\n",
    "    confusion_matrix(y_val, y_pred),\n",
    "    index=np.unique(y),\n",
    "    columns=np.unique(y)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b18199e-b765-496a-ad4d-d1b0be32b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE  # For handling class imbalance\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    "    min_samples_split=int(1e3)\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, \n",
    "                          target_names=label_encoder.classes_,\n",
    "                          zero_division=0))\n",
    "\n",
    "# Predictions\n",
    "results = df_imputed.iloc[val_indices].copy()\n",
    "results['Predicted'] = label_encoder.inverse_transform(y_pred)\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(results[[TARGET_COLUMN] + FEATURE_COLUMNS + ['Predicted']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97136a-7711-4f04-a87e-bc6ad1a72173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE  # For handling class imbalance\n",
    "\n",
    "# 1. Handle Class Imbalance\n",
    "smote = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. Train Model with Balanced Data and Optimized Parameters\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=1000,  # Increased from 100\n",
    "    max_depth=8,      # Increased from 7\n",
    "    min_samples_split=int(1e2),  # Reduced from 1000\n",
    "    class_weight='balanced_subsample',  # Added class weighting\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all cores\n",
    ")\n",
    "\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 3. Enhanced Evaluation\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(\"\\n=== Enhanced Evaluation ===\")\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "\n",
    "# Detailed class performance\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, \n",
    "                          target_names=label_encoder.classes_,\n",
    "                          zero_division=0))\n",
    "\n",
    "# Confusion matrix for error analysis\n",
    "print(\"\\nConfusion Matrix (True vs Predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_val, y_pred),\n",
    "      index=label_encoder.classes_,\n",
    "      columns=label_encoder.classes_))\n",
    "\n",
    "# 4. Predictions with Confidence\n",
    "probs = model.predict_proba(X_val)\n",
    "results = df_filtered.iloc[val_indices].copy()\n",
    "results['Predicted'] = label_encoder.inverse_transform(y_pred)\n",
    "results['Confidence'] = np.max(probs, axis=1)  # Add confidence scores\n",
    "\n",
    "print(\"\\nSample Predictions with Confidence Scores:\")\n",
    "print(results[[TARGET_COLUMN] + FEATURE_COLUMNS + ['Predicted', 'Confidence']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea84a89-1974-474d-a087-1063a0ba14ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration\n",
    "TARGET_COLUMN = 'SubClass'  # Changed to string since it's a single column\n",
    "FEATURE_COLUMNS = ['Teff2', 'logg2', 'Rad']\n",
    "\n",
    "# Prepare data - no label encoding needed since subclasses are already numeric\n",
    "y = df_filtered[TARGET_COLUMN].astype(int)  # Ensure integer type\n",
    "X = df_filtered[FEATURE_COLUMNS]\n",
    "\n",
    "# Get class names for reporting\n",
    "class_names = sorted(y.unique())\n",
    "\n",
    "# Split data (stratified)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, \n",
    "                                                 stratify=y, random_state=42)\n",
    "\n",
    "# 1. Handle Class Imbalance automatically with SMOTE\n",
    "smote = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. Train Model with Balanced Data and Optimized Parameters\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,  # Increased for better performance\n",
    "    max_depth=10,      # Increased depth for more complex relationships\n",
    "    min_samples_leaf=5, # Added to prevent overfitting\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42,\n",
    "    n_jobs=-1          # Re-enabled parallel processing\n",
    ")\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 3. Enhanced Evaluation\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(\"\\n=== Enhanced Evaluation ===\")\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, \n",
    "                          target_names=[str(c) for c in class_names],\n",
    "                          zero_division=0))\n",
    "\n",
    "print(\"\\nConfusion Matrix (True vs Predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_val, y_pred),\n",
    "                  index=class_names,\n",
    "                  columns=class_names))\n",
    "\n",
    "# 4. Predictions with Confidence\n",
    "probs = model.predict_proba(X_val)\n",
    "results = df_filtered.iloc[X_val.index].copy()\n",
    "results['Predicted'] = y_pred\n",
    "results['Confidence'] = np.max(probs, axis=1)\n",
    "\n",
    "print(\"\\nSample Predictions with Confidence Scores:\")\n",
    "print(results[[TARGET_COLUMN] + FEATURE_COLUMNS + ['Predicted', 'Confidence']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d9488b-f4e0-4e9c-87ff-a423391bff02",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be3146c-a30d-443b-9577-15698d62a7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df32059-47e6-4dbb-9025-1a221cdf40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.impute import KNNImputer\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# def knn_impute_with_categorical(df, n_neighbors=5):\n",
    "#     \"\"\"\n",
    "#     Applies KNN imputation while preserving categorical columns.\n",
    "    \n",
    "#     Parameters:\n",
    "#     df (pd.DataFrame): Input dataframe with mixed data types\n",
    "#     n_neighbors (int): Number of neighbors for KNN\n",
    "    \n",
    "#     Returns:\n",
    "#     pd.DataFrame: Imputed dataframe with original dtypes preserved\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Create copy to avoid modifying original\n",
    "#     df_imputed = df.copy()\n",
    "    \n",
    "#     # Identify categorical and numerical columns\n",
    "#     categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "#     numerical_cols = df.select_dtypes(include=np.number).columns\n",
    "    \n",
    "#     # Label encode categorical columns\n",
    "#     encoders = {}\n",
    "#     for col in categorical_cols:\n",
    "#         le = LabelEncoder()\n",
    "#         df_imputed[col] = le.fit_transform(df[col].astype(str))\n",
    "#         encoders[col] = le\n",
    "    \n",
    "#     # Apply KNN imputation to all columns (now numerical)\n",
    "#     imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "#     imputed_data = imputer.fit_transform(df_imputed)\n",
    "#     df_imputed = pd.DataFrame(imputed_data, columns=df.columns)\n",
    "    \n",
    "#     # Convert categorical columns back to original labels\n",
    "#     for col in categorical_cols:\n",
    "#         df_imputed[col] = encoders[col].inverse_transform(df_imputed[col].round().astype(int))\n",
    "    \n",
    "#     # Restore original dtypes\n",
    "#     for col, dtype in df.dtypes.items():\n",
    "#         if col in categorical_cols:\n",
    "#             df_imputed[col] = df_imputed[col].astype(dtype)\n",
    "#         else:\n",
    "#             df_imputed[col] = df_imputed[col].astype(dtype) if dtype != object else df_imputed[col]\n",
    "    \n",
    "#     return df_imputed\n",
    "\n",
    "# # Usage example:\n",
    "# df_imputed = knn_impute_with_categorical(df1, n_neighbors=5)\n",
    "df_imputed = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63253bfd-7ebd-4d5f-a4f9-547518d755d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove categories with 10 or fewer elements\n",
    "value_counts = df_imputed['Ca_K'].value_counts()  # Replace 'Ca_K' with your target column\n",
    "valid_categories = value_counts[value_counts > 1000].index\n",
    "df_filtered = df_imputed[df_imputed['Ca_K'].isin(valid_categories)].copy()  # Replace 'Ca_K'\n",
    "\n",
    "# Pre-removal\n",
    "print(\"Categories:\")\n",
    "print(df_imputed['Ca_K'].value_counts())  # Replace 'Ca_K'\n",
    "\n",
    "# Verify removal\n",
    "print(\"Remaining categories:\")\n",
    "print(df_filtered['Ca_K'].value_counts())  # Replace 'Ca_K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb82a5a8-7c2c-4208-a2ed-57614801b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999bbaa4-3642-4f83-a42f-ed45f6336353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Configuration\n",
    "TARGET_COLUMN = 'Ca_K'\n",
    "FEATURE_COLUMNS = ['Teff2', 'logg1', 'FeH1', 'Vmag', 'Rad', 'Miss']\n",
    "MAX_SAMPLES_PER_CLASS = int(1e4)  # Customizable\n",
    "\n",
    "# Prepare balanced training set\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_filtered[TARGET_COLUMN])\n",
    "X = df_filtered[FEATURE_COLUMNS]\n",
    "\n",
    "# Stratified sampling with class balancing\n",
    "balanced_samples = []\n",
    "for class_id in np.unique(y):\n",
    "    class_indices = np.where(y == class_id)[0]\n",
    "    n_samples = min(MAX_SAMPLES_PER_CLASS, len(class_indices))\n",
    "    \n",
    "    if len(class_indices) < MAX_SAMPLES_PER_CLASS:\n",
    "        # Sample WITH replacement for small classes\n",
    "        sampled_indices = np.random.choice(class_indices, \n",
    "                                         size=MAX_SAMPLES_PER_CLASS, \n",
    "                                         replace=True)\n",
    "    else:\n",
    "        # Sample WITHOUT replacement for large classes\n",
    "        sampled_indices = np.random.choice(class_indices, \n",
    "                                         size=MAX_SAMPLES_PER_CLASS, \n",
    "                                         replace=False)\n",
    "    \n",
    "    balanced_samples.extend(sampled_indices)\n",
    "\n",
    "X_train = X.iloc[balanced_samples]\n",
    "y_train = y[balanced_samples]\n",
    "\n",
    "# Remaining data for validation\n",
    "val_indices = list(set(range(len(df_filtered))) - set(balanced_samples))\n",
    "X_val = X.iloc[val_indices]\n",
    "y_val = y[val_indices]\n",
    "\n",
    "# Verify counts\n",
    "print(\"Training set class counts:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\nOriginal class distribution:\")\n",
    "print(pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de63b92-ca0c-4858-adb5-01431fcd1958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Configuration\n",
    "TARGET_COLUMN = 'Ca_K'\n",
    "FEATURE_COLUMNS = ['Teff2', 'logg2', 'Vmag', 'Rad', 'Miss']\n",
    "MAX_SAMPLES_PER_CLASS = 2100  # Customizable\n",
    "\n",
    "# Prepare balanced training set\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_filtered[TARGET_COLUMN])\n",
    "X = df_filtered[FEATURE_COLUMNS]\n",
    "\n",
    "# Stratified sampling with equal class sizes\n",
    "balanced_samples = []\n",
    "for class_id in np.unique(y):\n",
    "    class_indices = np.where(y == class_id)[0]\n",
    "    sampled_indices = np.random.choice(class_indices, \n",
    "                                     size=min(MAX_SAMPLES_PER_CLASS, len(class_indices)), \n",
    "                                     replace=False)\n",
    "    balanced_samples.extend(sampled_indices)\n",
    "\n",
    "X_train = X.iloc[balanced_samples]\n",
    "y_train = y[balanced_samples]\n",
    "\n",
    "# Remaining data for validation\n",
    "val_indices = list(set(range(len(df_filtered))) - set(balanced_samples))\n",
    "X_val = X.iloc[val_indices]\n",
    "y_val = y[val_indices]\n",
    "\n",
    "# Verify counts\n",
    "print(\"Training set class counts:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99efecd-4edf-4d8a-8032-2ea91e70232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE  # For handling class imbalance\n",
    "\n",
    "# 1. Handle Class Imbalance\n",
    "smote = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. Train Model with Balanced Data and Optimized Parameters\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=1000,  # Increased from 100\n",
    "    max_depth=8,      # Increased from 7\n",
    "    min_samples_split=int(1e2),  # Reduced from 1000\n",
    "    class_weight='balanced_subsample',  # Added class weighting\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all cores\n",
    ")\n",
    "\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 3. Enhanced Evaluation\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(\"\\n=== Enhanced Evaluation ===\")\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "\n",
    "# Detailed class performance\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, \n",
    "                          target_names=label_encoder.classes_,\n",
    "                          zero_division=0))\n",
    "\n",
    "# Confusion matrix for error analysis\n",
    "print(\"\\nConfusion Matrix (True vs Predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_val, y_pred),\n",
    "      index=label_encoder.classes_,\n",
    "      columns=label_encoder.classes_))\n",
    "\n",
    "# 4. Predictions with Confidence\n",
    "probs = model.predict_proba(X_val)\n",
    "results = df_filtered.iloc[val_indices].copy()\n",
    "results['Predicted'] = label_encoder.inverse_transform(y_pred)\n",
    "results['Confidence'] = np.max(probs, axis=1)  # Add confidence scores\n",
    "\n",
    "print(\"\\nSample Predictions with Confidence Scores:\")\n",
    "print(results[[TARGET_COLUMN] + FEATURE_COLUMNS + ['Predicted', 'Confidence']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f945b-de0e-40ed-b297-2fb53047c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    "    min_samples_split=int(1e3)\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, \n",
    "                          target_names=label_encoder.classes_,\n",
    "                          zero_division=0))\n",
    "\n",
    "# Predictions\n",
    "results = df_filtered.iloc[val_indices].copy()\n",
    "results['Predicted'] = label_encoder.inverse_transform(y_pred)\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(results[[TARGET_COLUMN] + FEATURE_COLUMNS + ['Predicted']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01986f9-dd8f-4792-9dc9-db46319b4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# XGBoost hyperparameter tuning\n",
    "params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.5,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(np.unique(y_train)),\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'early_stopping_rounds': 10,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Train with validation monitoring\n",
    "model = XGBClassifier(**params)\n",
    "eval_set = [(X_train, y_train), (X_val, y_val)]\n",
    "model.fit(X_train, y_train,\n",
    "          eval_set=eval_set,\n",
    "          verbose=True)\n",
    "\n",
    "# Retrieve and print training history\n",
    "results = model.evals_result()\n",
    "epochs = len(results['validation_0']['mlogloss'])\n",
    "x_axis = range(0, epochs)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_axis, results['validation_0']['mlogloss'], label='Train')\n",
    "plt.plot(x_axis, results['validation_1']['mlogloss'], label='Validation')\n",
    "plt.legend()\n",
    "plt.ylabel('Log Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('XGBoost Training Progress')\n",
    "plt.show()\n",
    "\n",
    "# Best iteration\n",
    "best_iter = model.best_iteration\n",
    "print(f\"\\nBest iteration: {best_iter}\")\n",
    "print(f\"Best params: {model.get_params()}\")\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred,\n",
    "                          target_names=label_encoder.classes_,\n",
    "                          zero_division=0))\n",
    "\n",
    "# Feature importance\n",
    "plt.figure(figsize=(10, 5))\n",
    "xgb.plot_importance(model)\n",
    "plt.show()\n",
    "\n",
    "# Predictions\n",
    "results = df_filtered.iloc[val_indices].copy()\n",
    "results['Predicted'] = label_encoder.inverse_transform(y_pred)\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(results[[TARGET_COLUMN] + FEATURE_COLUMNS + ['Predicted']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6cbe0-ca0b-4421-a4d8-27f7dc12f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#model = SVC()\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Customizable configuration - CHANGE HERE TO MODIFY FEATURES\n",
    "TARGET_COLUMN = 'Ca_K'  # Column to predict\n",
    "FEATURE_COLUMNS = ['Teff2', 'logg1', 'FeH1', 'Vmag', 'Rad','Miss']  # Features to use (modify as needed)\n",
    "\n",
    "class SimpleStellarClassifier:\n",
    "    def __init__(self, target_col, feature_cols):\n",
    "        self.target_col = target_col\n",
    "        self.feature_cols = feature_cols\n",
    "        self.model = None\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "    def train(self, df):\n",
    "        \"\"\"Train model with 70/30 random split\"\"\"\n",
    "        # Prepare data\n",
    "        X = df_filtered[self.feature_cols]\n",
    "        y = self.label_encoder.fit_transform(df_filtered[self.target_col])\n",
    "        \n",
    "        # Split data (70% train, 30% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.4, random_state=30\n",
    "        )\n",
    "        \n",
    "        # Train Random Forest (simpler than XGBoost)\n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=500,  # 100 trees\n",
    "            max_depth=10,      # Limit tree depth\n",
    "            random_state=42,\n",
    "            min_samples_split = 100,\n",
    "            #class_weight = 'balanced_subsample'\n",
    "        )\n",
    "        # self.model = SVC(\n",
    "        #     kernel='rbf',          # radial basis function kernel (handles non-linearity)\n",
    "        #     C=1.0,                 # regularization (lower = simpler model)\n",
    "        #     gamma='scale',         # auto setting for RBF kernel\n",
    "        #     class_weight='balanced',  # handle class imbalance\n",
    "        #     probability=True,      # enables probability estimates\n",
    "        #     random_state=42\n",
    "        # )\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        # Validate\n",
    "        y_pred = self.model.predict(X_val)\n",
    "        print(\"\\nValidation Metrics:\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_val, y_pred, \n",
    "                                 target_names=self.label_encoder.classes_,\n",
    "                                 zero_division=0))\n",
    "    \n",
    "    def predict(self, df):\n",
    "        \"\"\"Make predictions on new data\"\"\"\n",
    "        pred_encoded = self.model.predict(df[self.feature_cols])\n",
    "        return self.label_encoder.inverse_transform(pred_encoded)\n",
    "\n",
    "# Usage:\n",
    "# 1. Initialize with your target and features\n",
    "classifier = SimpleStellarClassifier(\n",
    "    target_col=TARGET_COLUMN,\n",
    "    feature_cols=FEATURE_COLUMNS\n",
    ")\n",
    "\n",
    "# 2. Train and validate\n",
    "classifier.train(df_filtered)\n",
    "\n",
    "# 3. Make predictions\n",
    "predictions = classifier.predict(df_filtered)\n",
    "results = df_filtered[[TARGET_COLUMN] + FEATURE_COLUMNS].copy()\n",
    "results['Predicted'] = predictions\n",
    "\n",
    "# Show first 10 predictions\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(results.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4264806-06c9-45f0-85f5-51ca9c64a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "\n",
    "# Configuration - MODIFY HERE\n",
    "TARGET_COLUMN = 'Ca_K'  # Column to predict\n",
    "#FEATURE_COLUMNS = ['Teff1','FeH1','Vmag','logg1','Lum','Miss']  # Features to use\n",
    "#FEATURE_COLUMNS = ['Teff1','Miss']  # Features to use\n",
    "\n",
    "class OptimizedStellarClassifier:\n",
    "    def __init__(self, target_col, feature_cols):\n",
    "        self.target_col = target_col\n",
    "        self.feature_cols = feature_cols\n",
    "        self.model = None\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.best_params = {}\n",
    "        \n",
    "    def _calculate_optimal_depth(self, y):\n",
    "        \"\"\"Determine max_depth based on target cardinality\"\"\"\n",
    "        n_classes = len(np.unique(y))\n",
    "        base_depth = [4, 10, 15, 20, 25, 30]  # Custom depth array - modify values as needed\n",
    "        return {\n",
    "            'max_depth': base_depth,\n",
    "            'n_estimators': [10,100,500]\n",
    "        }\n",
    "        \n",
    "    def train(self, df):\n",
    "        \"\"\"Train model with optimized max_depth\"\"\"\n",
    "        # Prepare data\n",
    "        X = df[self.feature_cols]\n",
    "        y = self.label_encoder.fit_transform(df[self.target_col])\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Determine depth range based on target classes\n",
    "        param_grid = self._calculate_optimal_depth(y)\n",
    "        print(f\"Testing parameters: {param_grid}\")\n",
    "        \n",
    "        # Grid search for best parameters\n",
    "        grid = GridSearchCV(\n",
    "            RandomForestClassifier(\n",
    "                class_weight='balanced_subsample',\n",
    "                random_state=42\n",
    "            ),\n",
    "            param_grid,\n",
    "            cv=3,\n",
    "            scoring='accuracy'\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        \n",
    "        self.model = grid.best_estimator_\n",
    "        self.best_params = grid.best_params_\n",
    "        \n",
    "        # Validation\n",
    "        y_pred = self.model.predict(X_val)\n",
    "        print(\"\\n=== Best Parameters ===\")\n",
    "        print(f\"max_depth: {self.best_params['max_depth']}\")\n",
    "        print(f\"n_estimators: {self.best_params['n_estimators']}\")\n",
    "        \n",
    "        print(\"\\n=== Validation Metrics ===\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_val, y_pred,\n",
    "                                 target_names=self.label_encoder.classes_,\n",
    "                                 zero_division=0))\n",
    "    \n",
    "    def predict(self, df):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        pred_encoded = self.model.predict(df[self.feature_cols])\n",
    "        return self.label_encoder.inverse_transform(pred_encoded)\n",
    "\n",
    "# Usage\n",
    "classifier = OptimizedStellarClassifier(\n",
    "    target_col=TARGET_COLUMN,\n",
    "    feature_cols=FEATURE_COLUMNS\n",
    ")\n",
    "\n",
    "# Train with automatic depth tuning\n",
    "classifier.train(df_filtered)\n",
    "\n",
    "# Predictions\n",
    "predictions = classifier.predict(df_filtered)\n",
    "results = df_filtered[[TARGET_COLUMN] + FEATURE_COLUMNS].copy()\n",
    "results['Predicted'] = predictions\n",
    "\n",
    "print(\"\\n=== First 10 Predictions ===\")\n",
    "print(results.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a65ba6-5db6-416d-b7c4-4ae939c6d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: classes (3000 cada), com depth = 20 deu 0.74 o melhor\n",
    "# 3: classes, maxdepth = 10, 500 estimadores, max deu 0.7529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db09dc8-1f14-4d4b-9146-821e78493f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f51be-b7aa-40d6-ab8f-7f64d8652e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ed81f-3ba3-4ded-8cb0-4a5aa8666c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc8da27-3b6a-40e6-9ba8-7537242a4ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
